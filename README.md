# GRUPO-11

<h1 align="center"> PROYECTO FINAL </h1>
<h1 align="center"> Detecci√≥n de piletas utilizando im√°genes satelitales y Deep Learning </h1>

### COHORTE 2022

### :globe_with_meridians: TECNICATURA EN CIENCIAS DE DATOS E INTELIGENCIA ARTIFICIAL

### *Colaboradores:*

- [Hanun Romina](https://github.com/RomiHanun) 
- [Kanneman Samuel](https://github.com/samuelkanneman)
- [Zelaray√°n Rom√°n ](https://github.com/romanzelararg)
- [Mansilla Leonardo Matias ](https://github.com/LMmansilla)
- [Lucero Carla](https://github.com/CarlaLucerocd)
- [Juchniewicz Federico](https://github.com/FJISPC)

![ImagenSatelital](https://github.com/romanzelararg/GRUPO-11---Proyecto-Final-Cohorte-2022-/blob/main/img_SAS_wgs_r.jpg)

### :pushpin: *El procesamiento de im√°genes, combinado con machine learning, ofrece un gran potencial para la ciencia de datos. Un ejemplo de aplicaci√≥n y uso para la Gestion Urbana es la detecci√≥n de piletas.*

# :black_nib: *Modelo de Referencia CRISP-DM*
## 1. Comprensi√≥n del Negocio
   >Objetivos y requisitos del Proyecto, definici√≥n del problema y plan preliminar dise√±ado.

:paperclip: ***Mediante el framework Raster Vision se propone realizar el procedimiento completo de aprendizaje profundo geoespacial:***
- [x] Leer datos georreferenciados
- [x] Entrenar modelos
- [x] Realizar predicciones
- [x] Escribir predicciones en formatos georreferenciados.

üíª ***Desarrollar un sistema automatizado que use:***

‚úÖ Im√°genes satelitales de alta resoluci√≥n para identificar posibles piletas

‚úÖ Algoritmos de aprendizaje profundo, entrenados para reconocer formas y reflejos de agua en las im√°genes.

:space_invader: ***Objetivo del sistema automatizado***

El objetivo es que dicho sistema pueda identificar piscinas en im√°genes satelitales de alta resoluci√≥n. √âste sistema podr√≠a ser de gran utilidad para entidades recaudadoras de impuestos, ya que permitir√≠a identificar propiedades con piscinas que no est√°n declaradas, lo que podr√≠a ayudar a reducir la evasi√≥n fiscal y aumentar la equidad tributaria.

Adem√°s, el sistema tambi√©n podr√≠a ayudar a optimizar los recursos utilizados en la fiscalizaci√≥n, ya que permitir√≠a identificar las propiedades que deben ser inspeccionadas de manera m√°s eficiente.


:pencil: ***Identificaci√≥n de las partes interesadas y sus necesidades***

*Partes interesadas:*

* Entidades recaudadoras: Buscan utilizar el sistema para reducir la evasi√≥n fiscal, aumentar la equidad tributaria y optimizar recursos en la fiscalizaci√≥n.

* Equipo de desarrollo del proyecto: Incluye a Romina Yael Hanun, Federico Juchniewicz, Samuel Kanneman, Carla Lucero, Leonardo Mat√≠as Mansilla y Rom√°n Zelaray√°n, quienes est√°n a cargo de desarrollar y entrenar el modelo de deep learning.

* Usuarios finales: Podr√≠an ser analistas urbanos o autoridades municipales interesadas en la gesti√≥n y planificaci√≥n urbana.

*Necesidades:*

* Automatizaci√≥n y precisi√≥n: Desarrollar un sistema automatizado que utilice im√°genes satelitales de alta resoluci√≥n y algoritmos de aprendizaje profundo para identificar piletas con precisi√≥n.
  
* Procesamiento de datos geoespaciales: Implementar un procedimiento completo de aprendizaje profundo geoespacial que incluya la lectura de datos georreferenciados, entrenamiento de modelos, realizaci√≥n de predicciones y escritura de predicciones en formatos georreferenciados.
  
* Acceso y manejo de datos: Utilizar herramientas como Raster Vision y GDAL para manejar datos raster y vectoriales, y asegurar el acceso a datos almacenados en AWS S3 sin necesidad de autenticaci√≥n.
  
* Visualizaci√≥n y evaluaci√≥n: Capacidad para visualizar los resultados de la segmentaci√≥n sem√°ntica y evaluar la precisi√≥n del modelo.
  

Identificar los posibles beneficios y desafios del proyecto:

El proyecto descrito tiene como objetivo utilizar im√°genes satelitales y t√©cnicas de deep learning para detectar piscinas, lo que puede tener varios beneficios y desaf√≠os:

Beneficios:

Automatizaci√≥n en la detecci√≥n: El uso de algoritmos de aprendizaje profundo puede automatizar y acelerar el proceso de identificaci√≥n de piscinas en grandes √°reas geogr√°ficas.
Mejora en la gesti√≥n urbana: La detecci√≥n precisa de piscinas puede ayudar a las entidades recaudadoras a reducir la evasi√≥n fiscal y aumentar la equidad tributaria.
Optimizaci√≥n de recursos: El sistema propuesto podr√≠a optimizar los recursos utilizados en la fiscalizaci√≥n, haciendo el proceso m√°s eficiente.

Desaf√≠os:

Calidad de los datos: La precisi√≥n del modelo depende de la calidad y resoluci√≥n de las im√°genes satelitales, as√≠ como de la precisi√≥n de las anotaciones utilizadas para el entrenamiento.
Complejidad t√©cnica: Implementar y mantener un sistema de aprendizaje profundo requiere conocimientos especializados y puede ser t√©cnicamente desafiante.
Cambios ambientales: Las condiciones ambientales y cambios estacionales pueden afectar la visibilidad de las piscinas en las im√°genes satelitales, lo que podr√≠a complicar la detecci√≥n.

Mediante el framework Raster Vision se propone realizar el procedimiento completo de aprendizaje profundo geoespacial

üíæ Mediante el framework Raster Vision se propone realizar el procedimiento completo de aprendizaje profundo geoespacial:
Leer datos georreferenciados
Entrenar modelos
Realizar predicciones
Escribir predicciones en formatos georreferenciados.
    
      
## 2. Comprensi√≥n de los Datos
   >Recopilaci√≥n , primeros conocimientos de los datos

Objetivo: An√°lisis exploratorio de las im√°genes satelitales que tenemos disponibles.
An√°lisis exploratorio de las im√°genes satelitales del √°rea de inter√©s. Implica visualizar las im√°genes, entender su resoluci√≥n y otros metadatos.

Exploraci√≥n de herramientas de descarga.
Descarga de im√°genes satelitales para entrenamiento.
Instalaci√≥n de librer√≠as de RasterVision
Carga de im√°genes satelitales en Drive
Identificar las fuentes de datos y proyecciones
Dataset de evidencia de campo (relevamiento de piscinas) fue obtenido de la p√°gina web del gobierno de la Ciudad de Buenos Aires. (https://buenosaires.gob.ar/). El mismo consisti√≥ en:

‚Äå

Datos georreferenciados: Estos datos, que pueden incluir informaci√≥n sobre la ubicaci√≥n de las piscinas, se utilizan para entrenar el modelo y evaluar su rendimiento;
Datos de entrenamiento y validaci√≥n: Estos son subconjuntos de los datos georreferenciados que se utilizan espec√≠ficamente para entrenar el modelo y evaluar su rendimiento durante el proceso de entrenamiento.
Es importante mencionar que el cuaderno no especifica exactamente de d√≥nde se obtienen estos datos. Sin embargo, en proyectos similares, las im√°genes satelitales a menudo se obtienen de fuentes como Google Earth, Bing Maps, o servicios de im√°genes satelitales como Sentinel o Landsat. Los datos georreferenciados pueden provenir de diversas fuentes, incluyendo bases de datos p√∫blicas o privadas, o pueden ser recopilados manualmente.


Realizar un an√°lisis exploratorio de los datos.

Se descarga y se guarda un archivo .geojson, que es un formato de archivo abierto para representar datos geoespaciales simples.
Los archivos GeoJSON contienen informaci√≥n geogr√°fica, como puntos, l√≠neas y pol√≠gonos, junto con otros datos en formato JSON;
Se configura las clases para la segmentaci√≥n, se define el tama√±o de las ventanas de entrenamiento y establece una serie de transformaciones de aumento de datos para mejorar la robustez del modelo de aprendizaje autom√°tico.
Las transformaciones de aumento de datos son t√©cnicas comunes para aumentar artificialmente la diversidad de los datos de entrenamiento sin recopilar nuevos datos, lo que puede mejorar la capacidad del modelo para generalizar a nuevas im√°genes.


Identificar las caracter√≠sticas y la calidad de los datos.

Caracter√≠sticas y la calidad de los datos:

Caracter√≠sticas del Proyecto:

Objetivo: Utilizar el procesamiento de im√°genes y machine learning para detectar piletas en im√°genes satelitales.
Framework Utilizado: Raster Vision, para el proceso completo de aprendizaje profundo geoespacial.
Fuente de Datos: Im√°genes satelitales de la p√°gina web del gobierno de la Ciudad de Buenos Aires.
Aplicaci√≥n Propuesta: Implementaci√≥n por entidades recaudadoras para reducir la evasi√≥n fiscal y optimizar recursos.
Calidad y Configuraci√≥n de Datos:

Dataset: Alta resoluci√≥n, obtenido de una fuente gubernamental confiable.
Preprocesamiento: Uso de GDAL para leer y escribir datos geoespaciales.
Clases Definidas: Dos clases, 'background' y 'pileta', con sus respectivas transformaciones y visualizaci√≥n.
Calidad del C√≥digo:

Estructura: El c√≥digo est√° bien organizado, con comentarios explicativos y secciones claramente definidas.
Modelo de Deep Learning: Utiliza un modelo preentrenado de PyTorch con configuraciones espec√≠ficas para la tarea.
Visualizaci√≥n: Incluye c√≥digo para visualizar los resultados de la segmentaci√≥n sem√°ntica.
Entrenamiento del Modelo: Configura y entrena el modelo con un conjunto de datos de entrenamiento y validaci√≥n.
Posibles Mejoras:

Validaci√≥n de Datos: Asegurarse de que las anotaciones y etiquetas sean precisas.
Optimizaci√≥n de Hiperpar√°metros: Ajustar los hiperpar√°metros para mejorar el rendimiento del modelo.
Evaluaci√≥n Rigurosa: Implementar m√©tricas de evaluaci√≥n para medir la precisi√≥n y el recall del modelo.

Definir las clases para la segmentaci√≥n

En el contexto de la segmentaci√≥n sem√°ntica en deep learning, las "clases" se refieren a las categor√≠as de objetos que el modelo est√° dise√±ado para reconocer en las im√°genes. Cada p√≠xel en la imagen se clasifica en una de las clases posibles.

En el colab ISPC_Piletas_Entrenamiento.ipynb`, las clases para la segmentaci√≥n probablemente ser√≠an al menos dos: 'pileta' (piscina) y 'background' (fondo). Esto significa que el modelo est√° entrenado para reconocer y diferenciar entre estas dos categor√≠as en las im√°genes satelitales.

La clase 'pileta' corresponder√≠a a los p√≠xeles que representan piscinas en las im√°genes.
La clase 'background' corresponder√≠a a todos los dem√°s p√≠xeles que no representan piscinas.
Estas clases permiten al modelo aprender a distinguir entre las caracter√≠sticas visuales de las piscinas y el resto de la imagen. Una vez entrenado, el modelo puede aplicarse a nuevas im√°genes para identificar y segmentar las piscinas.

## 3. Preparaci√≥n de los Datos
   >Seleccion de tablas, registros y atributos, transformaci√≥n y limpieza de datos.
Preparar los datos para el modelado:
Implica la limpieza de las im√°genes, la evaluaci√≥n del dataset (evaluaci√≥n visual de correspondencia de las anotaciones), la eliminaci√≥n de las partes no deseadas y la preparaci√≥n de las etiquetas para el entrenamiento del modelo.
>
Definici√≥n de nuestra √°rea de inter√©s
El √Årea de Inter√©s (AoI) se refiere a la regi√≥n geogr√°fica espec√≠fica que se est√° analizando o estudiando. En nuestro caso, est√° relacionada con la detecci√≥n de piletas (piscinas) utilizando im√°genes satelitales y t√©cnicas de aprendizaje profundo.

El AoI se define mediante un archivo GeoJSON, que es un formato de archivo abierto para representar datos geoespaciales simples. Este archivo contiene informaci√≥n geogr√°fica, como puntos, l√≠neas y pol√≠gonos, junto con otros datos en formato JSON. En el contexto del aprendizaje autom√°tico y el procesamiento de im√°genes, el AoI se utiliza para delimitar la regi√≥n sobre la cual el modelo realizar√° predicciones o an√°lisis.

En resumen, el AoI es crucial para enfocar el an√°lisis de datos geoespaciales en una regi√≥n espec√≠fica y es un componente esencial en proyectos de visi√≥n por computadora y teledetecci√≥n que involucran datos georreferenciados.

Entrenamiento del modelo 'resnet18'

Carga del Modelo Preentrenado:

Se carga un modelo resnet18 preentrenado utilizando torch.hub.
Se configura el modelo para la tarea espec√≠fica de segmentaci√≥n sem√°ntica con las clases definidas.
Entrenamiento del Modelo:

Se inicia el entrenamiento del modelo con los conjuntos de datos preparados.
Se realizan iteraciones (√©pocas) donde el modelo aprende a identificar piletas en las im√°genes.

Generaci√≥n de variable
En el caso del colab ISPC_Piletas_Entrenamiento.ipynb` , el c√≥digo muestra la generaci√≥n de dos variables:

annotations_url = "https://drive.google.com/file/d/1V9N0xDJKApR_p3PlFZ-9xSvMWWh1Xv3o/view?usp=drive_link"
annotations_file_dest = "/content/drive/MyDrive/Deteccion/anotaciones/anotaciones_wgs_geoj_r2.geojson"

Aqu√≠, annotations_url es una variable que almacena la URL del archivo que se desea descargar desde Google Drive, y annotations_file_dest es una variable que almacena la ruta donde se guardar√° el archivo descargado.

Preprocesar y Transformar los datos para su uso en el modelo.
Se empez√≥ a trabajar con una imagen que era bastante extensa de aproximadamente 40 manzanas pero se hizo dif√≠cil poder entrenar el modelo.
Por lo que reducimos la imagen a 4 manzanas y se logr√≥ entrenar correctamente.
Con dicho entrenamiento se obtuvo un modelo y se usos para predecir otro.

## 4. Modelado
   >Selecci√≥n y aplicaci√≥n varias t√©cnicas de modelado
>
Objetivo: Generaci√≥n del modelo deep learning.
Entrenar el modelo de deep learning utilizando el framework Raster Vision. Asegurarse de configurar correctamente los par√°metros del modelo y de utilizar una divisi√≥n adecuada de los datos para el entrenamiento y la validaci√≥n.

Seleccionar el modelo de aprendizaje profundo (ResNet-18).
ResNet-18 es una arquitectura de red neuronal convolucional que ha demostrado ser muy efectiva en tareas de reconocimiento de im√°genes. La versi√≥n "18" se refiere a la profundidad de la red, es decir, el n√∫mero de capas que tiene.

Las ResNets son conocidas por su capacidad para entrenar redes muy profundas gracias a sus "conexiones residuales" o "conexiones de salto". Estas conexiones permiten que el gradiente se propague directamente a trav√©s de varias capas sin atenuarse, lo que ayuda a mitigar el problema del "gradiente que desaparece", un problema com√∫n cuando se entrenan redes neuronales profundas.

En el contexto del colab ISPC_Piletas_Entrenamiento.ipynb, ResNet-18 ha sido seleccionado por varias razones:

Eficiencia: ResNet-18 es relativamente ligero en comparaci√≥n con otras variantes de ResNet (como ResNet-50, ResNet-101, etc.), lo que lo hace m√°s r√°pido y eficiente en t√©rminos de memoria y tiempo de c√°lculo.
Rendimiento: A pesar de su simplicidad, ResNet-18 puede ofrecer un rendimiento s√≥lido en muchas tareas de visi√≥n por computadora, incluyendo la detecci√≥n y segmentaci√≥n de objetos.
Preentrenamiento: ResNet-18 est√° disponible como un modelo preentrenado en varias bibliotecas de deep learning, lo que permite un inicio r√°pido y mejora el rendimiento al aprovechar los patrones aprendidos de grandes conjuntos de datos como ImageNet.

Configurar el modelo y los par√°metros de entrenamiento.

Selecci√≥n del Modelo: Se ha seleccionado ResNet-18, que es una arquitectura de red neuronal convolucional conocida por su eficacia en tareas de reconocimiento de im√°genes.

Configuraci√≥n de Par√°metros del Modelo: Los par√°metros del modelo, como el n√∫mero de capas y neuronas, as√≠ como las funciones de activaci√≥n, se configuran de acuerdo con las necesidades de la tarea.

Configuraci√≥n de Par√°metros de Entrenamiento: Los par√°metros de entrenamiento, como el n√∫mero de √©pocas, el tama√±o del lote y la tasa de aprendizaje, se establecen. Estos par√°metros pueden tener un gran impacto en la eficacia del entrenamiento.

Entrenar el modelo con los datos de entrenamiento.

Entrenamiento del Modelo: El modelo se entrena utilizando los datos de entrenamiento, ajustando los pesos y los par√°metros internos de la red para minimizar el error.

. Entrenamiento del Modelo:

Se inicia el entrenamiento del modelo con los conjuntos de datos preparados.
Se realizan iteraciones (epoch) donde el modelo aprende a identificar piletas en las im√°genes.

Monitorear el rendimiento del modelo durante el entrenamiento.

Visualizaci√≥n: Se utiliza SemanticSegmentationVisualizer para visualizar las predicciones del modelo y las etiquetas reales, lo que ayuda a monitorear c√≥mo el modelo est√° aprendiendo.
Registro de Estad√≠sticas: Se registran estad√≠sticas de los datos para asegurarse de que el entrenamiento se base en datos s√≥lidos y bien informados.
Guardado del Modelo: Una vez completado el entrenamiento, se guarda el modelo y su configuraci√≥n para su uso futuro.


## 5. Evaluaci√≥n
   >Evaluaci√≥n del modelo y revisi√≥n de los pasos ejecutados

## 6. Despliegue
    >Generar un informe o implementar un proceso

    
